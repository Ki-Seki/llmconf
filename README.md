# LLMConf

LLMConf unifies the loading and generation configurations of various LLM backends (e.g. `openai`, `transformers`), simplifying parameter control for experiments and testing.
